# Template for Math500 evaluation, mirroring the leaderboard/math setup.
dataset_path: json
process_docs: !function utils.process_docs
output_type: generate_until
doc_to_text: !function utils.doc_to_text
process_results: !function utils.process_results
doc_to_target: "{{answer if few_shot is undefined else solution}}"
generation_kwargs:
  until:
    - "Problem:"
    - "Solution:"
  do_sample: false
  temperature: 0
  max_gen_toks: 1024
metric_list:
  - metric: symbolic_accuracy
    aggregation: mean
    higher_is_better: true
  - metric: exact_string_accuracy
    aggregation: mean
    higher_is_better: true
num_fewshot: 4
metadata:
  version: 1.0
fewshot_config:
  sampler: first_n
  samples: !function utils.list_fewshot_samples